<html>

<head>

<link href='https://fonts.googleapis.com/css?family=Cabin:600|Nunito:400,300' rel='stylesheet' type='text/css'>

<title>Accepted Papers: Language Grounding for Robotics</title>

<link rel="stylesheet" href="workshop.css" type="text/css">

<style>
body {
background-color:#ffffff;
overflow-y: scroll;
}
hr.style2 {
	border-top: 3px double #8c8b8b;
}
</style>

</head>

<body>

<div class="center2">

<table class="center1">

<tr class="emptymargins">

<td>

<br><br>

</td>

</tr>

<tr class="emptymargins">

<td class="emptymargins">

<table class="emptymargins">

<tr class="emptymargins">

<td class="headername">

Accepted Papers: Language Grounding for Robotics

</td>

<td class="headerright">


Workshop at <a href="http://acl2017.org/">ACL 2017</a><br>
Vancouver, Canada<br>
Dates: August 3, 2017<br>


</td>

</tr>

</table>

</td>

</tr>

<tr>

<td class="menumainspace"><br></td>

</tr>





<tr class="emptymargins">

<td class="emptymargins">

<table class="mainpane2">

<tr class="emptymargins">

<td class="maintext2" style="padding-left: 35px; padding-right: 35px;">


<br>

The 1st workshop on <a href="https://robonlp2017.github.io/">Language Grounding for Robotics at ACL 2017</a> accepted the following papers:

<br>
<br>

**<strong>Regular Workshop Papers</strong>**

<br>
<br>

Interpreting Action-Based and Goal-Based Instructions in a Mobile-Manipulator Domain
Siddharth Karamcheti, Edward Clem Williams, Dilip Arumugam, Mina Rhee, Nakul Gopalan, Lawson L.S. Wong and Stefanie Tellex

<br>
<br>

Guiding Interaction Behaviors for Multi-modal Grounded Language Learning 
Jesse Thomason, Jivko Sinapov and Raymond Mooney

<br>
<br>

Grounding Language for Interactive Task Learning 
Peter Lindes, Aaron Mininger, James R. Kirk and John E. Laird

<br>
<br>

Towards Problem Solving Agents that Communicate and Learn 
Anjali Narayan-Chen, Colin Graber, Mayukh Das, Md Rakibul Islam, Soham Dan, Sriraam Natarajan, Janardhan Rao Doppa, Julia Hockenmaier, Martha Palmer and Dan Roth

<br>
<br>

Learning how to learn: an adaptive dialogue agent for incrementally learning visually grounded word meanings 
Yanchao Yu, Arash Eshghi and Oliver Lemon

<br>
<br>

Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task 
Matthew Marge, Claire Bonial, Ashley Foots, Cory Hayes, Cassidy Henry, Kimberly Pollard, Ron Artstein, Clare Voss and David Traum

<br>
<br>

Structured Learning for Context-aware Spoken Language Understanding of Robotic Commands 
Andrea Vanzo, Danilo Croce, Roberto Basili and Daniele Nardi

<br>
<br>

Natural Language Grounding and Grammar Induction for Robotic Manipulation Commands 
Muhannad Alomari, Paul Duckworth, Majd Hawasly, David C. Hogg and Anthony G. Cohn 

<br>
<br>

Communication with Robots using Multilayer Recurrent Networks 
Bedřich Pišl and David Mareček

<br>
<br>

Grounding Symbols in Multi-Modal Instructions 
Yordan Hristov, Svetlin Penkov, Alex Lascarides and Subramanian Ramamoorthy
	
<br>
<br>

Are distributional representations ready for the real world? Evaluating word vectors for grounded perceptual meaning 
Li Lucy and Jon Gauthier

<br>
<br>

Sympathy Begins with a Smile, Intelligence Begins with a Word: Use of Multimodal Features in Spoken Human-Robot Interaction 
Jekaterina Novikova, Christian Dondrup, Ioannis Papaioannou and Oliver Lemon

<br>
<br>

**<strong>Cross-Submission Papers</strong>**
	
<br>
<br>

Gated-Attention Architectures for Task-Oriented Language Grounding
Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal and Ruslan Salakhutdinov

<br>
<br>

Procedural Semantics - A Case Study in Locative Spatial Language (IROS 2015)
Michael Spranger

<br>
<br>

State Based Grounded Verb Semantic and Interactive Acquisition (ACL2017)
Lanbo She and Joyce Chai

<br>
<br>

Temporal Grounding Graphs for Language Understanding with Accrued Visual-Linguistic Context (IJCAI 2017)
Rohan Paul, Andrei Barbu, Sue Felshin, Boris Katz and Nicholas Roy

<br>
<br>

Grounding of Human Environments and Activities for Autonomous Robots (IJCAI 2017)
Muhannad Alomari, Paul Duckworth, Majd Hawasly, Nils Bore, David Hogg and Anthony Cohn

<br>
<br>

A Corpus of Natural Language for Visual Reasoning (ACL 2017)
Alane Suhr, Mike Lewis, James Yeh and Yoav Artzi

<br>
<br>

Situation Recognition: Visual Semantic Role Labeling for Image Understanding (CVPR 2016)
Mark Yatskar, Luke Zettlemoyer and Ali Farhadi

<br>
<br>
	

</td>

</tr>

</table>

</td>

</tr>

</table>

</div>

<br>

<br>

</body>

</html>
