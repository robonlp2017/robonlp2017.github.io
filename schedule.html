
<html>

<head>

<link href='https://fonts.googleapis.com/css?family=Cabin:600|Nunito:400,300' rel='stylesheet' type='text/css'>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-8024377-8', 'auto');
  ga('send', 'pageview');

</script>

<title>Schedule: Language Grounding for Robotics</title>

<link rel="stylesheet" href="workshop.css" type="text/css">

<style>
body {
background-color:#ffffff;
overflow-y: scroll;
}
hr.style2 {
	border-top: 3px double #8c8b8b;
}
</style>

</head>

<body>

<div class="center2">

<table class="center1">

<tr class="emptymargins">

<td>

<br><br>

</td>

</tr>

<tr class="emptymargins">

<td class="emptymargins">

<table class="emptymargins">

<tr class="emptymargins">

<td class="headername">

Schedule: Language Grounding for Robotics

</td>

<td class="headerright">


Workshop at <a href="http://acl2017.org/">ACL 2017</a><br>
Vancouver, Canada<br>
Dates: August 3, 2017<br>


</td>

</tr>

</table>

</td>

</tr>

<tr>

<td class="menumainspace"><br></td>

</tr>


<tr class="emptymargins">

<td class="emptymargins">

<table class="mainpane2">

<tr class="emptymargins">

<td class="maintext2" style="padding-left: 35px; padding-right: 35px;">


<br>
<strong>Schedule for the 1st workshop on <a href="https://robonlp2017.github.io/">Language Grounding for Robotics at ACL 2017</a></strong>:
<br><br>

<table style="table-layout:fixed;">
<tr><td style="width:110px">              </td><td></td><td><center><u>Slides</u></center></td></tr>
<tr><td style="width:110px">09:00 – 09:15:</td><td colspan=2>Welcome and Opening Remarks</td></tr>
<tr style="vertical-align:top"><td>09:15 – 09:50:</td><td style="width:220px"><a href="https://www.cse.msu.edu/~jchai/">Joyce Chai</a>, MSU:</td><td><font size="2">Teaching Robots New Tasks through Language Instructions</font></td></tr>
<tr style="vertical-align:top"><td>09:50 – 10:25:</td><td><a href="http://www.cs.utexas.edu/~mooney/">Ray Mooney</a>, UT Austin</td><td><font size="2"><a href="slides/ray_mooney.pptx">Robots that Learn Grounded Language Through Interactive Dialog</a></font></td><tr>
<tr style="vertical-align:top"><td>10:30 – 11:00:</td><td colspan=2>Coffee Break</td></tr>
<tr style="vertical-align:top"><td>11:00 – 11:35:</td><td><a href="http://cs.brown.edu/~stefie10/">Stefanie Tellex</a>, Brown</td><td><font size="2">Learning Models of Language, Action and Perception for Human-Robot Collaboration</font>
<tr style="vertical-align:top"><td>11:35 – 12:10</td><td><a href="http://groups.csail.mit.edu/rrg/">Nicholas Roy</a>, MIT</td><td><font size="2">Representations vs Algorithms: Symbols and Geometry in Robotics</font></td></tr>
<tr style="vertical-align:top"><td>12:10 – 14:00:</td><td>Poster Session:</td><td><font size="2">All Accepted Regular and Cross-Submission Papers Listed Below (Lunch from 12:30 – 14:00)</font></td></tr>
<tr style="vertical-align:top"><td>14:00 – 14:35:</td><td><a href="http://cs.stanford.edu/~pliang/">Percy Liang</a>, Stanford</td><td><font size="2"><a href="slides/percy_liang.pdf">Bridging the Language-Action Gap</a></font></td></tr>
<tr style="vertical-align:top"><td>14:35 – 15:10:</td><td><a href="http://www.thespermwhale.com/jaseweston/">Jason Weston</a>,<br/>Facebook AI Research </td><td><font size="2"><a href="slides/jason_weston.pptx">(End-to-End Methods for) Dialogue, Interaction and Learning</a></font></td></tr>

<tr style="vertical-align:top"><td>15:10 – 15:20:</td><td>Contributed Talk:</td><td> <font size="2">Yanchao Yu, Arash Eshghi and Oliver Lemon.</font> <font size="2">Learning how to Learn: An Adaptive Dialogue Agent for Incrementally Learning Visually Grounded Word Meanings.</font> </td></tr>
<tr style="vertical-align:top"><td>15:20 – 15:30:</td><td>Contributed Talk:</td><td><font size="2">Muhannad Alomari, Paul Duckworth, Majd Hawasly, David C. Hogg and Anthony G. Cohn.</font> <font size="2">Natural Language Grounding and Grammar Induction for Robotic Manipulation Commands.</font> </td></tr>

<tr><td>15:30 – 16:00:</td><td colspan=2>Mid-afternoon Snacks</td></tr>
<tr style="vertical-align:top"><td>16:00 – 16:10:</td><td>Contributed Talk:</td><td><font size="2">Siddharth Karamcheti, Edward Clem Williams, Dilip Arumugam, Mina Rhee, Nakul Gopalan, Lawson L.S. Wong and Stefanie Tellex.</font> <font size="2">A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions.</font> </td></tr>
<tr style="vertical-align:top"><td>16:10 – 16:45:</td><td><a href="http://www.karlmoritz.com/">Karl Moritz Hermann</a>, <br/>Google DeepMind</td><td><font size="2">Grounded Language Learning in Simulated Worlds</font></td></tr>
<tr style="vertical-align:top"><td>16:45 – 17:45:</td><td colspan=2>Panel (Jason, Joyce, Karl, Nicholas, Percy, Ray, Stefanie, Terry)</td></tr>
</table>
	
<hr>
<hr>

<br>
<b><font size="5">Accepted Regular Workshop Papers</font></b>
<br>
<p style="font-size:15px">
<b>Siddharth Karamcheti, Edward Clem Williams, Dilip Arumugam, Mina Rhee, Nakul Gopalan, Lawson L.S. Wong and Stefanie Tellex</b><br>
<i>Interpreting Action-Based and Goal-Based Instructions in a Mobile-Manipulator Domain</i><br>

<br>
<b>Jesse Thomason, Jivko Sinapov and Raymond Mooney</b><br>
<i>Guiding Interaction Behaviors for Multi-modal Grounded Language Learning</i><br>

<br>
<b>Peter Lindes, Aaron Mininger, James R. Kirk and John E. Laird</b><br>
<i>Grounding Language for Interactive Task Learning  </i><br>

<br>
<b>Anjali Narayan-Chen, Colin Graber, Mayukh Das, Md Rakibul Islam, Soham Dan, Sriraam Natarajan, Janardhan Rao Doppa, Julia Hockenmaier, Martha Palmer and Dan Roth</b><br>
<i>Towards Problem Solving Agents that Communicate and Learn </i> <br>

<br>
<b>Yanchao Yu, Arash Eshghi and Oliver Lemon</b><br>
<i>Learning how to learn: an adaptive dialogue agent for incrementally learning visually grounded word meanings </i><br>

<br>
<b>Matthew Marge, Claire Bonial, Ashley Foots, Cory Hayes, Cassidy Henry, Kimberly Pollard, Ron Artstein, Clare Voss and David Traum</b><br>
<i>Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task</i>  <br>

<br>
<b>Andrea Vanzo, Danilo Croce, Roberto Basili and Daniele Nardi</b><br>
<i>Structured Learning for Context-aware Spoken Language Understanding of Robotic Commands </i> <br>

<br>
<b>Muhannad Alomari, Paul Duckworth, Majd Hawasly, David C. Hogg and Anthony G. Cohn </b><br>
<i>Natural Language Grounding and Grammar Induction for Robotic Manipulation Commands </i> <br>

<br>
<b>Bedřich Pišl and David Mareček</b><br>
<i>Communication with Robots using Multilayer Recurrent Networks </i> <br>

<br>
<b>Yordan Hristov, Svetlin Penkov, Alex Lascarides and Subramanian Ramamoorthy</b><br>
<i>Grounding Symbols in Multi-Modal Instructions </i> <br>

<br>
<b>Li Lucy and Jon Gauthier</b><br>
<i>Are distributional representations ready for the real world? Evaluating word vectors for grounded perceptual meaning </i> <br>

<br>
<b>Jekaterina Novikova, Christian Dondrup, Ioannis Papaioannou and Oliver Lemon</b><br>
<i>Sympathy Begins with a Smile, Intelligence Begins with a Word: Use of Multimodal Features in Spoken Human-Robot Interaction </i> <br>

<br><br>
<b><font size="5">Accepted Cross-Submission Papers</font></b>
<br><br>

<b>Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal and Ruslan Salakhutdinov</b><br>
<i>Gated-Attention Architectures for Task-Oriented Language Grounding </i><br>

<br>
<b>Michael Spranger</b><br>
<i>Procedural Semantics - A Case Study in Locative Spatial Language (IROS 2015)</i> <br>

<br>
<b>Lanbo She and Joyce Chai</b><br>
<i>State Based Grounded Verb Semantic and Interactive Acquisition (ACL2017) </i><br>

<br>
<b>Rohan Paul, Andrei Barbu, Sue Felshin, Boris Katz and Nicholas Roy</b><br>
<i>Temporal Grounding Graphs for Language Understanding with Accrued Visual-Linguistic Context (IJCAI 2017) </i><br>

<br>
<b>Muhannad Alomari, Paul Duckworth, Majd Hawasly, Nils Bore, David Hogg and Anthony Cohn</b><br>
<i>Grounding of Human Environments and Activities for Autonomous Robots (IJCAI 2017) </i><br>

<br>
<b>Alane Suhr, Mike Lewis, James Yeh and Yoav Artzi</b><br>
<i>A Corpus of Natural Language for Visual Reasoning (ACL 2017) </i><br>

<br>
<b>Mark Yatskar, Luke Zettlemoyer and Ali Farhadi</b><br>
<i>Situation Recognition: Visual Semantic Role Labeling for Image Understanding (CVPR 2016) </i><br>
  
</p>
<br>
<br>


</td>
</tr>
</table>

</td>
</tr>
</table>
</div>

<br>
<br>

</body>
</html>
